{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 21:52:45.948910: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-19 21:52:46.024123: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-19 21:52:46.490495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-19 21:52:46.971506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:46.993254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:46.993291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:47.279735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:47.279785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:47.279795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:48.888994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:48.889067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:48.889074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-19 21:52:48.889089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 21:52:48.889223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6157 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from zlib import crc32\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "import stellargraph as sg \n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_index(steamid, graph_map):\n",
    "    if steamid in graph_map:\n",
    "        return graph_map[steamid]\n",
    "    else:\n",
    "        index = len(graph_map)\n",
    "        graph_map[steamid] = index\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_toxic(toxicities, map):\n",
    "    toxic_people_map = {}\n",
    "    for key in toxicities.keys():\n",
    "        data = toxicities[key]\n",
    "        count = 0\n",
    "        for element in data:\n",
    "            if (element >= 0.8):\n",
    "                count += 1\n",
    "        if count > 1:\n",
    "            toxic_people_map[key] = 1\n",
    "        else:\n",
    "            toxic_people_map[key] = 0\n",
    "    toxic = list(np.zeros(len(map)))\n",
    "    for key in toxic_people_map:\n",
    "        if key in map:\n",
    "            toxic[map[key]] = toxic_people_map[key]\n",
    "    return toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "    return bytes_to_float(s.encode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pymongo import MongoClient\n",
    "count = 2000\n",
    "client = MongoClient(\n",
    "f'mongodb://localhost:27017')\n",
    "mydb = client.get_database(\"toxic_games\")\n",
    "\n",
    "collection = mydb.get_collection(\"games\")\n",
    "\n",
    "player_graph = nx.Graph()\n",
    "\n",
    "steamid_to_index_graph = {}\n",
    "steamid_to_index_messages = {}\n",
    "index_to_toxicities = {}\n",
    "\n",
    "def add_toxicity(index, toxicity):\n",
    "    if index in index_to_toxicities:\n",
    "        index_to_toxicities[index].append(toxicity)\n",
    "    else:\n",
    "        index_to_toxicities[index] = [toxicity]\n",
    "\n",
    "# Create a graph\n",
    "\n",
    "for idx, item in enumerate(collection.find({\"lang\": \"Language.ENGLISH\"}).limit(count).allow_disk_use(True)):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    logdata = item[\"log\"]\n",
    "    players = list(logdata[\"players\"].keys())\n",
    "    for message in logdata[\"chat\"]:\n",
    "        if message[\"steamid\"] == \"Console\":\n",
    "            continue\n",
    "        sender = convert_to_index(\n",
    "            message[\"steamid\"], steamid_to_index_messages)\n",
    "        add_toxicity(message[\"steamid\"],\n",
    "                        message[\"detoxify-original\"][\"toxicity\"])\n",
    "    \n",
    "    blue_players = []\n",
    "    red_players = []\n",
    "    for key, value in logdata[\"players\"].items():\n",
    "        if value[\"team\"] == \"Red\":\n",
    "            red_players.append(key)\n",
    "        else:\n",
    "            blue_players.append(key)\n",
    "\n",
    "    for player_a in blue_players:\n",
    "        for player_b in blue_players:\n",
    "            if player_a != player_b:\n",
    "                id_a = convert_to_index(player_a, steamid_to_index_graph)\n",
    "                id_b = convert_to_index(player_b, steamid_to_index_graph)\n",
    "                if not player_graph.has_edge(id_a, id_b):\n",
    "                    player_graph.add_edge(id_a, id_b, weight=0.5)\n",
    "                else:\n",
    "                    player_graph[id_a][id_b][\"weight\"] += 0.5\n",
    "\n",
    "    for player_a in red_players:\n",
    "        for player_b in red_players:\n",
    "            if player_a != player_b:\n",
    "                id_a = convert_to_index(player_a, steamid_to_index_graph)\n",
    "                id_b = convert_to_index(player_b, steamid_to_index_graph)\n",
    "                if not player_graph.has_edge(id_a, id_b):\n",
    "                    player_graph.add_edge(id_a, id_b, weight=0.5)\n",
    "                else:\n",
    "                    player_graph[id_a][id_b][\"weight\"] += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicities = define_toxic(index_to_toxicities, steamid_to_index_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 4597, Edges: 25468\n",
      "\n",
      " Node types:\n",
      "  default: [4597]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [25468]\n",
      "        Weights: range=[1, 8], mean=1.10735, std=0.420006\n",
      "        Features: none\n",
      "4597\n"
     ]
    }
   ],
   "source": [
    "G = StellarGraph.from_networkx(player_graph)\n",
    "print(G.info())\n",
    "print(len(toxicities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks: 45970\n"
     ]
    }
   ],
   "source": [
    "weighted_walks = rw.run(\n",
    "    nodes=G.nodes(),  # root nodes\n",
    "    length=walk_length,  # maximum length of a random walk\n",
    "    n=10,  # number of random walks per root node\n",
    "    p=0.7,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=1,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "    weighted=True,  # for weighted random walks\n",
    "    seed=42,  # random seed fixed for reproducibility\n",
    ")\n",
    "print(\"Number of random walks: {}\".format(len(weighted_walks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = Word2Vec(\n",
    "    weighted_walks, vector_size=vector_size, window=5, min_count=0, sg=0, workers=4, epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_node_embeddings = weighted_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_embedding(index, own_steamid_to_index : dict):\n",
    "    steamid = \"\"\n",
    "    for key in own_steamid_to_index:\n",
    "        if own_steamid_to_index[key] == index:\n",
    "            steamid = key\n",
    "            break\n",
    "    if steamid in steamid_to_index_graph:\n",
    "        return weighted_node_embeddings[steamid_to_index_graph[steamid]]\n",
    "    else:\n",
    "        #print(\"Nothing\")\n",
    "        return np.ones(vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_number = {\n",
    "    \"NEUTRAL\": 0,\n",
    "    \"SLIGHTLY_TOXIC\": 1,\n",
    "    \"TOXIC\": 2,\n",
    "    \"EXTREMELY_TOXIC\": 3\n",
    "}\n",
    "\n",
    "\n",
    "def take_average(annotations):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for annotation in annotations:\n",
    "        if annotation != \"N_A\":\n",
    "            sum += label_to_number[annotation]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return -1\n",
    "    label = int(sum/count)\n",
    "    if label > 2:\n",
    "        label = 2\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "client = MongoClient(\n",
    "f'mongodb://localhost:27017')\n",
    "mydb = client.get_database(\"toxic_games\")\n",
    "\n",
    "collection = mydb.get_collection(\"games\")\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "steamid2_to_index_graph = {}\n",
    "features = []\n",
    "all_features = []\n",
    "graphs_train = []\n",
    "graphs_validation = []\n",
    "graph_labels = []\n",
    "nodes = []\n",
    "\n",
    "def get_team(players, player):\n",
    "    if player not in players:\n",
    "        return 0\n",
    "    if players[player][\"team\"] == \"Blue\":\n",
    "        return 1\n",
    "    else: \n",
    "        return 2\n",
    "\n",
    "for idx, item in enumerate(collection.find({\"lang\" : \"Language.ENGLISH\", \"problem\": {\"$exists\": False}}).limit(count).allow_disk_use(True)):\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "    logdata = item[\"log\"][\"events\"]\n",
    "    players = item[\"log\"][\"players\"]\n",
    "    \n",
    "    for index, event in enumerate(logdata):\n",
    "        nodes.append([1 if event[\"kill\"] else 0,1 if event[\"chargeUsed\"] else 0,1 if event[\"medicDrop\"] else 0,1 if event[\"message\"] else 0,1 if event[\"capture\"] else 0])\n",
    "        for index2, event2 in enumerate(logdata):\n",
    "            if index == index2 or (event[\"second\"] - event2[\"second\"] > 10 or event[\"second\"] - event2[\"second\"] < 0):\n",
    "                continue\n",
    "            if event[\"attacker\"] == event2[\"attacker\"]:\n",
    "                source.append(index)\n",
    "                target.append(index2)\n",
    "                player = convert_to_index(event[\"attacker\"], steamid2_to_index_graph)\n",
    "                feature = [1, get_team(players, event[\"attacker\"])]\n",
    "                feature.extend(get_node_embedding(player,steamid2_to_index_graph))\n",
    "                features.append(feature)\n",
    "            elif event[\"victim\"] and event[\"victim\"] == event2[\"victim\"]:\n",
    "                source.append(index)\n",
    "                target.append(index2)\n",
    "                feature = [0, get_team(players, event[\"victim\"])]\n",
    "                player = convert_to_index(event[\"victim\"], steamid2_to_index_graph)\n",
    "                feature.extend(get_node_embedding(player,steamid2_to_index_graph))\n",
    "                features.append(feature)\n",
    "    \n",
    "\n",
    "    players = list(set(target + source))\n",
    "    if (len(players) == 0):\n",
    "        source = []\n",
    "        target = []\n",
    "        nodes = []\n",
    "        features = []\n",
    "        steamid2_to_index_graph = {}\n",
    "        continue\n",
    "    \n",
    "    all_features.append(features)\n",
    "    toxic = 0\n",
    "    score = 0\n",
    "    toxic = take_average(item[\"annotation\"])\n",
    "    if toxic == -1:\n",
    "        source = []\n",
    "        target = []\n",
    "        nodes = []\n",
    "        features = []\n",
    "        steamid2_to_index_graph = {}\n",
    "        continue\n",
    "    graph_labels.append(toxic)\n",
    "    x = torch.tensor(nodes, dtype=torch.float32)\n",
    "    if item[\"type\"] == \"train\":\n",
    "        graphs_train.append(Data(x=x, edge_attr=torch.tensor(features, dtype=torch.float32), edge_index=torch.tensor([source, target], dtype=torch.long),y=torch.Tensor([toxic]).to(torch.long)))\n",
    "    else:\n",
    "        graphs_validation.append(Data(x=x, edge_attr=torch.tensor(features, dtype=torch.float32), edge_index=torch.tensor([source, target], dtype=torch.long),y=torch.Tensor([toxic]).to(torch.long)))\n",
    "    source = []\n",
    "    nodes=[]\n",
    "    target = []\n",
    "    features = []\n",
    "    steamid2_to_index_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "county = 0\n",
    "for graph in graphs_validation:\n",
    "    for edge_value in graph.edge_attr:\n",
    "        if torch.equal(edge_value[2:],torch.ones(128)):\n",
    "            county += 1\n",
    "print(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0       \n",
       "0    505\n",
       "1    111\n",
       "2     56"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(graph_labels).value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 518\n",
      "Number of validation graphs: 77\n",
      "Number of test graphs: 77\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "#dataset = graphs\n",
    "#split = int(len(dataset)*0.7)\n",
    "split = int(len(graphs_validation)*0.7)\n",
    "trainy = graphs_train.copy()\n",
    "trainy.extend(graphs_validation[:split])\n",
    "train_dataset = trainy#dataset[:split]\n",
    "\n",
    "remaining_dataset = graphs_validation[split:]#dataset[split:]\n",
    "remaining_split = int(len(remaining_dataset)*0.5)\n",
    "\n",
    "validation_dataset = remaining_dataset[:remaining_split]\n",
    "test_dataset = remaining_dataset[remaining_split:]\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(validation_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0       \n",
       "0     62\n",
       "1     11\n",
       "2      4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = list(map(lambda x: x.y.item(), validation_dataset))\n",
    "pd.DataFrame(val_y).value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4938, 5], edge_index=[2, 1429], edge_attr=[1429, 34], y=[16], batch=[4938], ptr=[17])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4384, 5], edge_index=[2, 1182], edge_attr=[1182, 34], y=[16], batch=[4384], ptr=[17])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4885, 5], edge_index=[2, 1586], edge_attr=[1586, 34], y=[16], batch=[4885], ptr=[17])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5229, 5], edge_index=[2, 1573], edge_attr=[1573, 34], y=[16], batch=[5229], ptr=[17])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4634, 5], edge_index=[2, 1392], edge_attr=[1392, 34], y=[16], batch=[4634], ptr=[17])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[6003, 5], edge_index=[2, 1840], edge_attr=[1840, 34], y=[16], batch=[6003], ptr=[17])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5786, 5], edge_index=[2, 1760], edge_attr=[1760, 34], y=[16], batch=[5786], ptr=[17])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4938, 5], edge_index=[2, 1569], edge_attr=[1569, 34], y=[16], batch=[4938], ptr=[17])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5734, 5], edge_index=[2, 1860], edge_attr=[1860, 34], y=[16], batch=[5734], ptr=[17])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5811, 5], edge_index=[2, 1866], edge_attr=[1866, 34], y=[16], batch=[5811], ptr=[17])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5504, 5], edge_index=[2, 2259], edge_attr=[2259, 34], y=[16], batch=[5504], ptr=[17])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5148, 5], edge_index=[2, 1447], edge_attr=[1447, 34], y=[16], batch=[5148], ptr=[17])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4268, 5], edge_index=[2, 1411], edge_attr=[1411, 34], y=[16], batch=[4268], ptr=[17])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5081, 5], edge_index=[2, 1421], edge_attr=[1421, 34], y=[16], batch=[5081], ptr=[17])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5351, 5], edge_index=[2, 1591], edge_attr=[1591, 34], y=[16], batch=[5351], ptr=[17])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5261, 5], edge_index=[2, 1522], edge_attr=[1522, 34], y=[16], batch=[5261], ptr=[17])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5257, 5], edge_index=[2, 1783], edge_attr=[1783, 34], y=[16], batch=[5257], ptr=[17])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5648, 5], edge_index=[2, 1556], edge_attr=[1556, 34], y=[16], batch=[5648], ptr=[17])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5685, 5], edge_index=[2, 1694], edge_attr=[1694, 34], y=[16], batch=[5685], ptr=[17])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5374, 5], edge_index=[2, 1608], edge_attr=[1608, 34], y=[16], batch=[5374], ptr=[17])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4547, 5], edge_index=[2, 1282], edge_attr=[1282, 34], y=[16], batch=[4547], ptr=[17])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5443, 5], edge_index=[2, 1758], edge_attr=[1758, 34], y=[16], batch=[5443], ptr=[17])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4848, 5], edge_index=[2, 2036], edge_attr=[2036, 34], y=[16], batch=[4848], ptr=[17])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[3877, 5], edge_index=[2, 1198], edge_attr=[1198, 34], y=[16], batch=[3877], ptr=[17])\n",
      "\n",
      "Step 25:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5376, 5], edge_index=[2, 1587], edge_attr=[1587, 34], y=[16], batch=[5376], ptr=[17])\n",
      "\n",
      "Step 26:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5469, 5], edge_index=[2, 1749], edge_attr=[1749, 34], y=[16], batch=[5469], ptr=[17])\n",
      "\n",
      "Step 27:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4737, 5], edge_index=[2, 1412], edge_attr=[1412, 34], y=[16], batch=[4737], ptr=[17])\n",
      "\n",
      "Step 28:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4612, 5], edge_index=[2, 1755], edge_attr=[1755, 34], y=[16], batch=[4612], ptr=[17])\n",
      "\n",
      "Step 29:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[5554, 5], edge_index=[2, 1845], edge_attr=[1845, 34], y=[16], batch=[5554], ptr=[17])\n",
      "\n",
      "Step 30:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4994, 5], edge_index=[2, 1420], edge_attr=[1420, 34], y=[16], batch=[4994], ptr=[17])\n",
      "\n",
      "Step 31:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4863, 5], edge_index=[2, 1896], edge_attr=[1896, 34], y=[16], batch=[4863], ptr=[17])\n",
      "\n",
      "Step 32:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[4385, 5], edge_index=[2, 1182], edge_attr=[1182, 34], y=[16], batch=[4385], ptr=[17])\n",
      "\n",
      "Step 33:\n",
      "=======\n",
      "Number of graphs in the current batch: 6\n",
      "DataBatch(x=[1933, 5], edge_index=[2, 663], edge_attr=[663, 34], y=[6], batch=[1933], ptr=[7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader.imbalanced_sampler import ImbalancedSampler\n",
    "\n",
    "train_loader = DataLoader(train_dataset, sampler=ImbalancedSampler(train_dataset), batch_size=16)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "max_degree = -1\n",
    "for data in train_dataset:\n",
    "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    max_degree = max(max_degree, int(d.max()))\n",
    "\n",
    "# Compute the in-degree histogram tensor\n",
    "deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "for data in train_dataset:\n",
    "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    deg += torch.bincount(d, minlength=deg.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, Linear, ModuleList, ReLU, Sequential, Dropout\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        aggregators = ['mean', 'min', 'max', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.batch_norms = ModuleList()\n",
    "        for _ in range(2):\n",
    "            conv = PNAConv(in_channels=5, out_channels=5,\n",
    "                           aggregators=aggregators, scalers=scalers, deg=deg,\n",
    "                           edge_dim=vector_size + 2, towers=5, pre_layers=1, post_layers=1,\n",
    "                           divide_input=False)\n",
    "            self.convs.append(conv)\n",
    "            self.batch_norms.append(BatchNorm(5))\n",
    "\n",
    "        self.mlp = Sequential(Linear(5, 5), ReLU(), Linear(5, 10), ReLU(),\n",
    "                              Linear(10, 3))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = x#self.node_emb(x.squeeze())\n",
    "        #edge_attr = self.edge_emb(edge_attr)\n",
    "\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = F.relu(batch_norm(conv(x, edge_index, edge_attr)))\n",
    "\n",
    "        x = global_add_pool(x, batch)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 3.0010, Val: 2.5232, Test: 2.4482 ROC: 0.4651\n",
      "Epoch: 02, Loss: 2.3206, Val: 1.7952, Test: 1.7893 ROC: 0.4985\n",
      "Epoch: 03, Loss: 1.7732, Val: 1.4432, Test: 1.5102 ROC: 0.5153\n",
      "Epoch: 04, Loss: 1.5824, Val: 1.2238, Test: 1.2457 ROC: 0.5196\n",
      "Epoch: 05, Loss: 1.4240, Val: 1.1732, Test: 1.1628 ROC: 0.5241\n",
      "Epoch: 06, Loss: 1.3003, Val: 1.2719, Test: 1.2604 ROC: 0.5229\n",
      "Epoch: 07, Loss: 1.2015, Val: 1.2939, Test: 1.2578 ROC: 0.5275\n",
      "Epoch: 08, Loss: 1.1297, Val: 1.0768, Test: 1.0442 ROC: 0.5129\n",
      "Epoch: 09, Loss: 1.1148, Val: 1.1537, Test: 1.1194 ROC: 0.5698\n",
      "Epoch: 10, Loss: 1.0775, Val: 1.2269, Test: 1.1416 ROC: 0.5647\n",
      "Epoch: 11, Loss: 1.0768, Val: 1.1995, Test: 1.1124 ROC: 0.5725\n",
      "Epoch: 12, Loss: 1.0738, Val: 1.2136, Test: 1.1441 ROC: 0.5890\n",
      "Epoch: 13, Loss: 1.0414, Val: 1.0823, Test: 1.0083 ROC: 0.5737\n",
      "Epoch: 14, Loss: 1.0318, Val: 1.3303, Test: 1.2451 ROC: 0.5717\n",
      "Epoch: 15, Loss: 1.0341, Val: 1.2774, Test: 1.1913 ROC: 0.5938\n",
      "Epoch: 16, Loss: 1.0087, Val: 1.1282, Test: 1.0420 ROC: 0.5857\n",
      "Epoch: 17, Loss: 1.0351, Val: 1.0985, Test: 1.0327 ROC: 0.5656\n",
      "Epoch: 18, Loss: 1.0411, Val: 1.0709, Test: 0.9876 ROC: 0.5824\n",
      "Epoch: 19, Loss: 1.0040, Val: 1.1724, Test: 1.0776 ROC: 0.5904\n",
      "Epoch: 20, Loss: 1.0186, Val: 1.1629, Test: 1.0752 ROC: 0.5995\n",
      "Epoch: 21, Loss: 1.0470, Val: 1.1121, Test: 1.0172 ROC: 0.5821\n",
      "Epoch: 22, Loss: 1.0213, Val: 1.0561, Test: 0.9705 ROC: 0.5736\n",
      "Epoch: 23, Loss: 1.0160, Val: 1.1539, Test: 1.0634 ROC: 0.5977\n",
      "Epoch: 24, Loss: 1.0029, Val: 1.1231, Test: 1.0102 ROC: 0.5873\n",
      "Epoch: 25, Loss: 1.0069, Val: 1.0722, Test: 0.9615 ROC: 0.5736\n",
      "Epoch: 26, Loss: 0.9920, Val: 1.1944, Test: 1.0874 ROC: 0.5885\n",
      "Epoch: 27, Loss: 1.0380, Val: 1.0532, Test: 0.9427 ROC: 0.5619\n",
      "Epoch: 28, Loss: 1.0237, Val: 1.1662, Test: 1.0407 ROC: 0.5907\n",
      "Epoch: 29, Loss: 0.9767, Val: 1.0643, Test: 0.9570 ROC: 0.5652\n",
      "Epoch: 30, Loss: 1.0344, Val: 1.2135, Test: 1.1182 ROC: 0.5877\n",
      "Epoch: 31, Loss: 0.9899, Val: 1.1376, Test: 1.0459 ROC: 0.5762\n",
      "Epoch: 32, Loss: 0.9960, Val: 1.1229, Test: 1.0540 ROC: 0.5631\n",
      "Epoch: 33, Loss: 0.9465, Val: 1.0697, Test: 0.9843 ROC: 0.5837\n",
      "Epoch: 34, Loss: 0.9705, Val: 1.1903, Test: 1.0922 ROC: 0.5952\n",
      "Epoch: 35, Loss: 0.9867, Val: 1.0177, Test: 0.9326 ROC: 0.5623\n",
      "Epoch: 36, Loss: 1.0000, Val: 1.0882, Test: 1.0102 ROC: 0.5964\n",
      "Epoch: 37, Loss: 0.9476, Val: 1.1477, Test: 1.0591 ROC: 0.5795\n",
      "Epoch: 38, Loss: 0.9351, Val: 1.1340, Test: 1.0144 ROC: 0.5599\n",
      "Epoch: 39, Loss: 0.9657, Val: 1.0081, Test: 0.9027 ROC: 0.5222\n",
      "Epoch: 40, Loss: 0.9878, Val: 1.1449, Test: 1.0211 ROC: 0.5586\n",
      "Epoch: 41, Loss: 0.9890, Val: 1.0626, Test: 0.9642 ROC: 0.5522\n",
      "Epoch: 42, Loss: 0.9978, Val: 1.1602, Test: 1.0547 ROC: 0.5604\n",
      "Epoch: 43, Loss: 0.9704, Val: 1.1790, Test: 1.0707 ROC: 0.5612\n",
      "Epoch: 44, Loss: 0.9158, Val: 0.9649, Test: 0.8783 ROC: 0.4926\n",
      "Epoch: 45, Loss: 0.9719, Val: 1.1215, Test: 1.0303 ROC: 0.5651\n",
      "Epoch: 46, Loss: 0.9504, Val: 1.1043, Test: 0.9905 ROC: 0.5551\n",
      "Epoch: 47, Loss: 0.9666, Val: 1.0590, Test: 0.9839 ROC: 0.5612\n",
      "Epoch: 48, Loss: 0.9358, Val: 1.1713, Test: 1.0549 ROC: 0.5484\n",
      "Epoch: 49, Loss: 0.9613, Val: 1.0261, Test: 0.9447 ROC: 0.5412\n",
      "Epoch: 50, Loss: 0.9675, Val: 1.1743, Test: 1.0525 ROC: 0.5395\n",
      "Epoch: 51, Loss: 0.9577, Val: 1.0773, Test: 0.9636 ROC: 0.5159\n",
      "Epoch: 52, Loss: 0.9396, Val: 1.1537, Test: 1.0842 ROC: 0.5571\n",
      "Epoch: 53, Loss: 0.9246, Val: 1.0634, Test: 1.0012 ROC: 0.5659\n",
      "Epoch: 54, Loss: 0.9339, Val: 1.0507, Test: 0.9606 ROC: 0.5631\n",
      "Epoch: 55, Loss: 0.9151, Val: 0.9487, Test: 0.8736 ROC: 0.5385\n",
      "Epoch: 56, Loss: 0.9117, Val: 1.0869, Test: 1.0128 ROC: 0.5553\n",
      "Epoch: 57, Loss: 0.8821, Val: 1.0795, Test: 1.0067 ROC: 0.5593\n",
      "Epoch: 58, Loss: 0.9459, Val: 0.9375, Test: 0.8754 ROC: 0.5332\n",
      "Epoch: 59, Loss: 0.9338, Val: 1.0502, Test: 0.9683 ROC: 0.5504\n",
      "Epoch: 60, Loss: 0.9214, Val: 1.0032, Test: 0.9165 ROC: 0.5374\n",
      "Epoch: 61, Loss: 0.8923, Val: 1.0281, Test: 0.9438 ROC: 0.5454\n",
      "Epoch: 62, Loss: 0.8998, Val: 1.0406, Test: 0.9641 ROC: 0.5475\n",
      "Epoch: 63, Loss: 0.9428, Val: 0.9827, Test: 0.9169 ROC: 0.5500\n",
      "Epoch: 64, Loss: 0.9525, Val: 0.9556, Test: 0.8866 ROC: 0.5427\n",
      "Epoch: 65, Loss: 0.9133, Val: 1.0919, Test: 1.0045 ROC: 0.5544\n",
      "Epoch: 66, Loss: 0.9238, Val: 1.0004, Test: 0.9203 ROC: 0.5436\n",
      "Epoch: 67, Loss: 0.8815, Val: 1.0683, Test: 0.9664 ROC: 0.5305\n",
      "Epoch: 68, Loss: 0.8965, Val: 1.0385, Test: 0.9444 ROC: 0.5353\n",
      "Epoch: 69, Loss: 0.8925, Val: 0.9305, Test: 0.8455 ROC: 0.5412\n",
      "Epoch: 70, Loss: 0.8745, Val: 1.0279, Test: 0.9291 ROC: 0.5324\n",
      "Epoch: 71, Loss: 0.9017, Val: 1.0066, Test: 0.9093 ROC: 0.5447\n",
      "Epoch: 72, Loss: 0.8987, Val: 1.0624, Test: 0.9659 ROC: 0.5305\n",
      "Epoch: 73, Loss: 0.9041, Val: 1.1036, Test: 0.9920 ROC: 0.5301\n",
      "Epoch: 74, Loss: 0.8752, Val: 1.0197, Test: 0.9155 ROC: 0.5351\n",
      "Epoch: 75, Loss: 0.8932, Val: 1.0161, Test: 0.9061 ROC: 0.5207\n",
      "Epoch: 76, Loss: 0.8825, Val: 1.0384, Test: 0.9338 ROC: 0.5380\n",
      "Epoch: 77, Loss: 0.8588, Val: 0.9844, Test: 0.8747 ROC: 0.5379\n",
      "Epoch: 78, Loss: 0.8767, Val: 1.0933, Test: 0.9749 ROC: 0.5370\n",
      "Epoch: 79, Loss: 0.8487, Val: 0.9907, Test: 0.8823 ROC: 0.5340\n",
      "Epoch: 80, Loss: 0.8846, Val: 1.2002, Test: 1.0780 ROC: 0.5273\n",
      "Epoch: 81, Loss: 0.8560, Val: 1.0685, Test: 0.9529 ROC: 0.5332\n",
      "Epoch: 82, Loss: 0.8405, Val: 1.0889, Test: 0.9606 ROC: 0.5289\n",
      "Epoch: 83, Loss: 0.8414, Val: 1.0041, Test: 0.8925 ROC: 0.5207\n",
      "Epoch: 84, Loss: 0.8504, Val: 1.0167, Test: 0.9014 ROC: 0.5249\n",
      "Epoch: 85, Loss: 0.8674, Val: 1.0205, Test: 0.9041 ROC: 0.5384\n",
      "Epoch: 86, Loss: 0.8967, Val: 1.0788, Test: 0.9514 ROC: 0.5383\n",
      "Epoch: 87, Loss: 0.8475, Val: 0.9957, Test: 0.8853 ROC: 0.5325\n",
      "Epoch: 88, Loss: 0.8458, Val: 0.9322, Test: 0.8343 ROC: 0.5298\n",
      "ROC 0.7176245210727968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f15f459a430>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, auc, confusion_matrix, f1_score, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10,\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        loss = loss_fn(out, data.y.to(torch.long))\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_error = 0\n",
    "    total_true = []\n",
    "    total_score = []\n",
    "    total_pred = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        total_error += loss_fn(out, data.y.to(torch.long)).item() * data.num_graphs\n",
    "        total_true.extend(data.y.tolist())\n",
    "        total_score.extend(out.softmax(dim=1).tolist())\n",
    "        total_pred.extend(out.softmax(dim=1).argmax(dim=1).tolist())\n",
    "\n",
    "    roc = roc_auc_score(total_true, total_score,average=\"macro\", multi_class='ovo')\n",
    "    cm = confusion_matrix(total_true, total_pred)\n",
    "    return total_error / len(loader.dataset), roc, cm\n",
    "\n",
    "\n",
    "for epoch in range(1, 301):\n",
    "    loss = train(epoch)\n",
    "    val_loss, roc, cm = test(validation_loader)\n",
    "    test_loss, test_roc, test_cm = test(test_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    if epoch >= 5:\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_roc = test_roc\n",
    "            best_cm = test_cm\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        if epoch_count >= 20:\n",
    "            break\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_loss:.4f}, Test: {test_loss:.4f} ROC: {roc:.4f}')\n",
    "print(\"ROC\",best_roc)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
